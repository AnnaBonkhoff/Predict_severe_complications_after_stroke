{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "\n",
    "def calibration(data, no_patients, no_patients_with_complication, downsampled_no_patients, downsampled_no_patients_with_complications):\n",
    "    \n",
    "    calibrated_data = \\\n",
    "    ((data * (no_patients_with_complication / no_patients) / (downsampled_no_patients_with_complications / downsampled_no_patients)) /\n",
    "    ((\n",
    "        (1 - data) * (1 - no_patients_with_complication / no_patients) / (1 - downsampled_no_patients_with_complications / downsampled_no_patients)\n",
    "     ) +\n",
    "     (\n",
    "        data * (no_patients_with_complication / no_patients) / (downsampled_no_patients_with_complications / downsampled_no_patients)\n",
    "     )))\n",
    "\n",
    "    return calibrated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_post = pd.read_csv(\"qs_2016_2017_prediction_mortality_211213.csv\", index_col=0)\n",
    "\n",
    "qs_post_2016 = qs_post[qs_post[\"dtjahr_a\"]==2016].copy()\n",
    "qs_post_2016 = qs_post_2016.drop(columns=[\"dtjahr_a\",])\n",
    "\n",
    "qs_post_2017 = qs_post[qs_post[\"dtjahr_a\"]==2017].copy()\n",
    "qs_post_2017 = qs_post_2017.drop(columns=[\"dtjahr_a\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_downsamples = 100\n",
    "inner_cv = 5\n",
    "\n",
    "all_preds_2016 = []\n",
    "all_y_2016 = []\n",
    "all_preds_2017 = []\n",
    "all_y_2017 = []\n",
    "\n",
    "tprs_2016 = []\n",
    "tprs_2017 = []\n",
    "test_auc_2016 = []\n",
    "test_auc_2017 = []\n",
    "test_auc_2017_cal = []\n",
    "\n",
    "fraction_pos_all_2017_cal = []\n",
    "mean_pred_all_2017_cal = []\n",
    "brier_score_all = []\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for no in range(no_downsamples):\n",
    "    qs_post_2016_0 = qs_post_2016[qs_post_2016[\"tot\"]==0].copy()\n",
    "    qs_post_2016_1 = qs_post_2016[qs_post_2016[\"tot\"]==1].copy()\n",
    "\n",
    "    qs_post_2016_0_sample = qs_post_2016_0.sample(int(np.sum(qs_post_2016[\"tot\"])), replace=False)\n",
    "    qs_post_2016_1_sample = qs_post_2016_1.sample(int(np.sum(qs_post_2016[\"tot\"])), replace=False)\n",
    "\n",
    "    qs_post_2016_joint = pd.concat([qs_post_2016_0_sample, qs_post_2016_1_sample])\n",
    "\n",
    "    y = np.array(qs_post_2016_joint[\"tot\"])\n",
    "    qs_post_2016_joint = qs_post_2016_joint.drop([\"tot\"], axis=1)\n",
    "    \n",
    "        \n",
    "    qs_post_2017_joint = qs_post_2017.copy()\n",
    "\n",
    "    y_2017 = np.array(qs_post_2017_joint[\"tot\"])\n",
    "    qs_post_2017_joint = qs_post_2017_joint.drop([\"tot\"], axis=1)\n",
    "\n",
    "                \n",
    "    pipe = Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                    ('classify',  KNeighborsClassifier())         \n",
    "                                    ])\n",
    "\n",
    "    parameters = [{\n",
    "                      'classify__n_neighbors': [1,5,10,50],\n",
    "                        }]\n",
    "    \n",
    "    clf = GridSearchCV(pipe,param_grid=parameters, cv =inner_cv)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(qs_post_2016_joint, y, test_size=0.2, random_state=no)\n",
    "\n",
    "    \n",
    "    clf.fit(X_train, np.array(y_train).ravel())\n",
    "    preds = clf.predict(X_test)\n",
    "    preds_2017 = clf.predict(qs_post_2017_joint)\n",
    "    all_preds_2016.append(preds)\n",
    "    all_y_2016.append(y_test)\n",
    "    all_preds_2017.append(preds_2017)\n",
    "    all_y_2017.append(np.array(y_2017).ravel())\n",
    "\n",
    "    y_proba_2016 = pd.DataFrame(clf.predict_proba(X_test)).loc[:,1]\n",
    "            \n",
    "    fpr_2016, tpr_2016, thresholds_2016 = roc_curve(y_test, y_proba_2016)\n",
    "    tprs_2016.append(np.interp(mean_fpr, fpr_2016, tpr_2016))\n",
    "    test_auc_2016.append(roc_auc_score(y_test, y_proba_2016))\n",
    "        \n",
    "    y_proba_2017 = pd.DataFrame(clf.predict_proba(qs_post_2017_joint)).loc[:,1]\n",
    "            \n",
    "    fpr_2017, tpr_2017, thresholds_2017 = roc_curve(y_2017, y_proba_2017)\n",
    "    tprs_2017.append(np.interp(mean_fpr, fpr_2017, tpr_2017))\n",
    "    test_auc_2017.append(roc_auc_score(y_2017, y_proba_2017))\n",
    "        \n",
    "    brier_score = brier_score_loss(y_2017, y_proba_2017, pos_label=y_2017.max())\n",
    "    brier_score_all.append(brier_score)\n",
    "\n",
    "    calibrated_y_proba_2017 = calibration(y_proba_2017, len(y_2017), np.sum(y_2017), len(y), np.sum(y))\n",
    "    fraction_of_positives_cal, mean_predicted_value_cal = calibration_curve(y_2017, calibrated_y_proba_2017, n_bins=10,strategy='quantile')\n",
    "    fraction_pos_all_2017_cal.append(fraction_of_positives_cal)\n",
    "    mean_pred_all_2017_cal.append(mean_predicted_value_cal)\n",
    "    test_auc_2017_cal.append(roc_auc_score(y_2017, calibrated_y_proba_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving prediction scores\n",
    "\n",
    "scores = pd.DataFrame(test_auc_2016)\n",
    "scores.columns = [\"validation_auc_2016\"]\n",
    "scores[\"auc_2017\"] = test_auc_2017\n",
    "scores[\"auc_cal_2017\"] = test_auc_2017_cal\n",
    "scores[\"brier_2017\"] = brier_score_all\n",
    "\n",
    "scores.to_csv(\"predictions/kNN_mortality_noICU_1111.csv\")\n",
    "\n",
    "tprs_long = pd.DataFrame(tprs_2017)\n",
    "tprs_long.to_csv(\"predictions/kNN_mortality_tprs_noICU_1111.csv\")\n",
    "\n",
    "fraction_pos_all_2017 = pd.DataFrame(fraction_pos_all_2017_cal)\n",
    "fraction_pos_all_2017.to_csv(\"predictions/kNN_mortality_fraction_pos_cal_noICU_1111.csv\")\n",
    "\n",
    "mean_pred_all_2017 = pd.DataFrame(mean_pred_all_2017_cal)\n",
    "mean_pred_all_2017.to_csv(\"predictions/kNN_mortality_mean_pred_cal_noICU_1111.csv\")\n",
    "\n",
    "pd.DataFrame(all_preds_2016).to_csv(\"predictions/kNN/kNN_mortality_all_pred_2016_noICU_1111.csv\")\n",
    "pd.DataFrame(all_preds_2017).to_csv(\"predictions/kNN/kNN_mortality_all_pred_2017_noICU_1111.csv\")\n",
    "pd.DataFrame(all_y_2016).to_csv(\"predictions/kNN/kNN_mortality_all_y_2016_noICU_1111.csv\")\n",
    "pd.DataFrame(all_y_2017).to_csv(\"predictions/kNN/kNN_mortality_all_y_2017_noICU_1111.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
