{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "\n",
    "def calibration(data, no_patients, no_patients_with_complication, downsampled_no_patients, downsampled_no_patients_with_complications):\n",
    "    \n",
    "    calibrated_data = \\\n",
    "    ((data * (no_patients_with_complication / no_patients) / (downsampled_no_patients_with_complications / downsampled_no_patients)) /\n",
    "    ((\n",
    "        (1 - data) * (1 - no_patients_with_complication / no_patients) / (1 - downsampled_no_patients_with_complications / downsampled_no_patients)\n",
    "     ) +\n",
    "     (\n",
    "        data * (no_patients_with_complication / no_patients) / (downsampled_no_patients_with_complications / downsampled_no_patients)\n",
    "     )))\n",
    "\n",
    "    return calibrated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_post = pd.read_csv(\"qs_2016_2017_prediction_mortality_211213.csv\", index_col=0)\n",
    "\n",
    "qs_post_2016 = qs_post[qs_post[\"dtjahr_a\"]==2016].copy()\n",
    "qs_post_2016 = qs_post_2016.drop(columns=[\"dtjahr_a\",])\n",
    "qs_post_2017 = qs_post[qs_post[\"dtjahr_a\"]==2017].copy()\n",
    "qs_post_2017 = qs_post_2017.drop(columns=[\"dtjahr_a\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = []\n",
    "\n",
    "all_preds_2016 = []\n",
    "all_y_2016 = []\n",
    "all_preds_2017 = []\n",
    "all_y_2017 = []\n",
    "\n",
    "tprs_2016 = []\n",
    "tprs_2017 = []\n",
    "test_auc_2016 = []\n",
    "test_auc_2017 = []\n",
    "\n",
    "\n",
    "fraction_pos_all_2017 = []\n",
    "mean_pred_all_2017 = []\n",
    "brier_score_all = []\n",
    "\n",
    "fraction_pos_all_2017_cal = []\n",
    "mean_pred_all_2017_cal = []\n",
    "test_auc_2017_cal = []\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for no in range(1):\n",
    "    qs_post_2016_0 = qs_post_2016[qs_post_2016[\"tot\"]==0].copy()\n",
    "    qs_post_2016_1 = qs_post_2016[qs_post_2016[\"tot\"]==1].copy()\n",
    "\n",
    "    qs_post_2016_0_sample = qs_post_2016_0.sample(int(np.sum(qs_post_2016[\"tot\"])), replace=False)\n",
    "    qs_post_2016_1_sample = qs_post_2016_1.sample(int(np.sum(qs_post_2016[\"tot\"])), replace=False)\n",
    "\n",
    "    qs_post_2016_joint = pd.concat([qs_post_2016_0_sample, qs_post_2016_1_sample])\n",
    "\n",
    "    y = np.array(qs_post_2016_joint[\"tot\"])\n",
    "    qs_post_2016_joint = qs_post_2016_joint.drop([\"tot\"], axis=1)\n",
    "    \n",
    "    qs_post_2017_joint = qs_post_2017.copy()\n",
    "\n",
    "    y_2017 = np.array(qs_post_2017_joint[\"tot\"])\n",
    "    qs_post_2017_joint = qs_post_2017_joint.drop([\"tot\"], axis=1)\n",
    "                \n",
    "    pipe = Pipeline([\n",
    "               ('scale', StandardScaler()),\n",
    "                    ('classify', GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                       max_features='log2'))         \n",
    "                                    ])\n",
    "            \n",
    "    N_ESTIMATORS = [100, 300, 500]\n",
    "    MAX_DEPTH = [1,3, 5]\n",
    "    LOSS = ['deviance', 'exponential']\n",
    "    \n",
    "                \n",
    "    parameters = {'classify__n_estimators': N_ESTIMATORS, \n",
    "                  'classify__max_depth': MAX_DEPTH,\n",
    "                  'classify__loss': LOSS}\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(qs_post_2016_joint, y, test_size=0.2, random_state=no)\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(pipe,param_grid=parameters, cv=5)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    preds = clf.predict(X_test)\n",
    "    preds_2017 = clf.predict(qs_post_2017_joint)\n",
    "    all_preds_2016.append(preds)\n",
    "    all_y_2016.append(y_test)\n",
    "    all_preds_2017.append(preds_2017)\n",
    "    all_y_2017.append(np.array(y_2017).ravel())\n",
    "        \n",
    "    y_proba_2016 = pd.DataFrame(clf.predict_proba(X_test)).loc[:,1]\n",
    "            \n",
    "    fpr_2016, tpr_2016, thresholds_2016 = roc_curve(y_test, y_proba_2016)\n",
    "    tprs_2016.append(np.interp(mean_fpr, fpr_2016, tpr_2016))\n",
    "    test_auc_2016.append(roc_auc_score(y_test, y_proba_2016))\n",
    "        \n",
    "    y_proba_2017 = pd.DataFrame(clf.predict_proba(qs_post_2017_joint)).loc[:,1]\n",
    "            \n",
    "    fpr_2017, tpr_2017, thresholds_2017 = roc_curve(y_2017, y_proba_2017)\n",
    "    tprs_2017.append(np.interp(mean_fpr, fpr_2017, tpr_2017))\n",
    "    test_auc_2017.append(roc_auc_score(y_2017, y_proba_2017))\n",
    "        \n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_2017, y_proba_2017, n_bins=10)\n",
    "    brier_score = brier_score_loss(y_2017, y_proba_2017, pos_label=y_2017.max())\n",
    "    brier_score_all.append(brier_score)\n",
    "    fraction_pos_all_2017.append(fraction_of_positives)\n",
    "    mean_pred_all_2017.append(mean_predicted_value)\n",
    "        \n",
    "    calibrated_y_proba_2017 = calibration(y_proba_2017, len(y_2017), np.sum(y_2017), 8092, 4046)\n",
    "    fraction_of_positives_cal, mean_predicted_value_cal = calibration_curve(y_2017, calibrated_y_proba_2017, n_bins=100,strategy='quantile')\n",
    "    fraction_pos_all_2017_cal.append(fraction_of_positives_cal)\n",
    "    mean_pred_all_2017_cal.append(mean_predicted_value_cal)\n",
    "    test_auc_2017_cal.append(roc_auc_score(y_2017, calibrated_y_proba_2017))\n",
    "    \n",
    "\n",
    "    feature_importances = np.append(feature_importances, clf.best_estimator_.named_steps[\"classify\"].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8092\n",
      "4046.0\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71184\n",
      "3637.0\n"
     ]
    }
   ],
   "source": [
    "print(len(y_2017))\n",
    "print(np.sum(y_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('clf_mortality.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
